{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4_ecllctG5s",
        "outputId": "ed8c6e61-a814-4d74-ec93-985a2defdeef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKvHMnaotSws",
        "outputId": "e7c42c64-da2f-496a-85e8-1e94321eceaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import wordnet\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "AR25nev2toPW",
        "outputId": "20947c15-02bd-4466-d558-d043767e5f9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2676e433-4128-4f7d-8d41-d21f22fdf031\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2676e433-4128-4f7d-8d41-d21f22fdf031\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CW_DataSet.csv to CW_DataSet.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aVBhXIDZuQUm",
        "outputId": "57b79d62-5afe-471b-fdd1-6f5136ae9a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   article_id                                               text\n",
              "0           1  'Abhorrent' bottle attack on young Rangers fan...\n",
              "1           2  'Afghan Girl' in iconic National Geographic ph...\n",
              "2           3  'My whole family has been wiped out': Victims ...\n",
              "3           4  'RHONY' STAR JULES WAINSTEIN Estranged Husband...\n",
              "4           5  'Swam for their life': More survivors of Levia..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee4f7e80-d604-454a-8df0-9fd3bb521db6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>'Abhorrent' bottle attack on young Rangers fan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>'Afghan Girl' in iconic National Geographic ph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>'My whole family has been wiped out': Victims ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>'RHONY' STAR JULES WAINSTEIN Estranged Husband...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>'Swam for their life': More survivors of Levia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee4f7e80-d604-454a-8df0-9fd3bb521db6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee4f7e80-d604-454a-8df0-9fd3bb521db6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee4f7e80-d604-454a-8df0-9fd3bb521db6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da0ac9db-508b-4965-88fc-9af157fee719\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da0ac9db-508b-4965-88fc-9af157fee719')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da0ac9db-508b-4965-88fc-9af157fee719 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 418,\n  \"fields\": [\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120,\n        \"min\": 1,\n        \"max\": 418,\n        \"num_unique_values\": 418,\n        \"samples\": [\n          322,\n          325,\n          389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"The Democratic Party Has Exploded \\u2014  The Democratic Party exploded Tuesday night.   There will be months of finger-pointing and internal reprisals over exactly what Democrats should have done differently. But the shocking thoroughness of the defeat is plain. Donald Trump \\u2015 a man who opened his presidential campaign by calling Mexicans \\u201crapists\\u201d \\u2015 bested Mitt Romney\\u2019s share of the Latino vote by 8 percentage points. He performed better among black voters than his 2012 predecessor, and he swept four Rust Belt states that President Barack Obama carried twice \\u2015 Pennsylvania, Ohio, Michigan and Wisconsin \\u2015 under a harsher economy than we face today. Hillary Clinton won the popular vote, which should matter, but does not.   How did this happen, and what now?   The exit polls provide some clarity: A significant chunk of Obama voters flipped to Trump. Trump won 10 percent of voters who approve of Obama\\u2019s presidency and 23 percent of voters who think the next president should \\u201cbe more liberal,\\u201d according to CNN data. Trump significantly outperformed Romney among union households. He did 14 points better than Romney among whites without a college degree, according to The New York Times, and 16 points better among households with less than $30,000 in income. The Trump Democrat turns out not to be a myth, but a meaningful constituency that just cost Clinton the presidency. Optimistic Democrats have long believed the voter coalition behind Obama \\u2015 young people, brown people, lower-income people and a sprinkling of white professionals \\u2015 was a stable and growing majority that could always put Democrats over the top. Instead, its success in 2008 and 2012 may have had more to do with a uniquely talented politician who also happened to be the first black president.   Obama also glued together two otherwise hostile ideological factions within the Democratic Party. Time magazine hailed him as the second coming of Franklin Delano Roosevelt, while he declared himself a member of the corporate-friendly, free-trading New Democrat coalition. Millions of Americans who love Sens. Bernie Sanders (I-Vt.) and Elizabeth Warren (D-Mass.) also love Obama. So do well-heeled technocrats who admire President Bill Clinton and economist Larry Summers.   This was reflected in Obama\\u2019s policy achievements. He expanded access to health insurance for millions of people and signed trade deals that undermined workers and enriched CEOs.   That same duality permeates Congress, where New Democrats have been battling New Dealers for 45 years. It is simply not clear that another politician is capable of keeping that team united.   Here\\u2019s how things were supposed to work: Clinton would call the shots, but work with Warren on cabinet appointments and key administrative posts. Things wouldn\\u2019t always go Warren\\u2019s way, but Clinton would throw enough bones to the populists to keep them engaged. Clinton could pursue a centrist agenda with a few progressive items and the party would stick together.     Instead, a dominance struggle between Sanders supporters and the Steny Hoyer wing of the party is already underway. Raul Grijalva, co-chair of the Congressional Progressive Caucus, is calling for a \\u201ccomplete restructuring\\u201d of the Democratic National Committee, and Sanders is promoting nominees.   The Clintons have been on the national stage for nearly a quarter of a century. An entire generation of Democratic operatives has grown up in a world in which it was always understood that the family would be a nexus of political power. This cohort expected to inherit the levers of government and is now without a patron. That fact, for the moment, gives progressives the upper hand in directing the party\\u2019s future. But because Democrats are certain to suffer devastating policy defeats under Trump and a GOP Congress, there will be no legislative victories that either faction can point to as proof its worldview can work. And further electoral losses are on the horizon. The 2018 map is terrible for Democrats \\u2015 five of their senators are up for re-election in Republican-dominated states, and four more in swing states. The losing side in the party leadership battle will be pissed off for a long time.   The American left, meanwhile, is a difficult beast to corral. The Sanders coalition wasn\\u2019t monolithic \\u2015 it included plenty of New Dealer populists, but it also brought in capital-S hammer-and-sickle Socialists who don\\u2019t really like the Democratic Party. Even under a progressive takeover, we can expect the bitter intellectual feuds between Bernie Bros and Hillary Bots to shift down the ideological spectrum.   Many are interpreting Trump\\u2019s election as a white supremacist backlash against the first black president and misogynist fear of a first woman president. After Trump\\u2019s vile campaign, it is impossible to conclude these were not significant factors.   But ugly attitudes don\\u2019t simply fall out of the sky, eternal and inflexible. A new paper from economists Rob Johnson and Arjun Jayadev looks at economic downturns from 1979 to 2014, and finds a tight correlation between unemployment and racism \\u2015 the higher the unemployment rate, the more ubiquitous the discrimination. A 2014 study from New York University psychologists found that racial animosity hardens under economic scarcity. Last year, three German economists found that \\u201cfar-right\\u201d political parties almost always make significant gains after a financial crisis.   This doesn\\u2019t mean that economic insecurity is the sole cause of racism, but it does suggest that it can be a cause. They call it the Rust Belt for a reason. If Democrats want to stamp out the views that made President Trump possible, they will have to do a better job delivering economic gains to working people.   \\u201cWe have been fighting out elections in general on a lot of noneconomic issues over the past 30 years,\\u201d Clinton recently told the New Yorker\\u2019s George Packer. \\u201cWe haven\\u2019t had a coherent, compelling economic case.\\u201d   Indeed.\",\n          \"The Flint of California \\u2014  Once a month, the residents of Matheny Tract, one of hundreds of poor and largely Latino enclaves tucked deep in California\\u2019s Central Valley, gather in the shade of a neighbor\\u2019s carport, chihuahuas dozing at their feet. The subject of their meetings is always the same: water. As long as they\\u2019ve lived here, the water that comes out of their taps has been contaminated with arsenic and other chemicals; they refuse to drink it, and the very act of taking a shower can make them feel unclean.   \\u201cIt tastes like watered-down bleach,\\u201d says Reinelda Palma, a longtime community leader whose house hosts the gatherings. \\u201cI don\\u2019t even wash plates with it. My biggest worry is that kids drink it.\\u201d   The Flint lead crisis has made us think of tainted water as an urban problem, aging pipes slowly poisoning the children of poor communities. But a huge amount of America\\u2019s substandard drinking water is actually consumed in all but invisible rural areas like Matheny Tract. Roughly a third of the 1,200 or so people here live in poverty, some in tattered doublewides on the brink of collapse. Already in precarious financial circumstances, they find themselves paying twice for water\\u2014once for the tainted well water coming out of the tap, and then again for bottled water they can actually drink.   But after decades of political neglect, Matheny Tract and similar communities are now at the forefront of legislation built on a legal idea that has gained increasing attention in the past decade in the developing world: the \\u201chuman right to water.\\u201d   In 2012, California became the first state in the U.S. to legally declare that every human being has the right to \\u201csafe, clean, affordable, and accessible water adequate for human consumption, cooking and sanitary purposes.\\u201d The bill, signed by Gov. Jerry Brown and similar to one vetoed by his Republican predecessor, Arnold Schwarzenegger, was largely symbolic, intended as a moral compass for future water policy. But it contained a key provision, requiring state agencies to consider the human right to water when establishing new regulations and grant programs.   Matheny Tract, an unincorporated community outside the city of Tulare (pop.: 61,000), is not a household word in California\\u2014or even Tulare, about two miles away. Yet Matheny is about to make history of a sort: It will be the first community to receive better water under SB88, the most significant piece of legislation thus far to be framed by the Human Right to Water bill. The new law gives the state authority to order cities to consolidate their water systems with poor unincorporated neighbors stuck with tainted water\\u2014in this case, meaning their water will soon be supplied by nearby Tulare. So in the next few weeks, the beleaguered residents of Matheney are due to receive the same clean water that people a couple of miles away for the most part have never had to think twice about.   An identical law has been introduced in Michigan, where class-action attorneys have descended on Flint\\u2014part of a 15-bill package of legislation that also deals with billing, service shut-offs and other affordability issues. But those bills are still stuck in committee. So, for now, California is the lone front in America where this radical expansion of human rights is advancing, albeit slowly, and raising the question of whether \\u201crights\\u201d might someday improve communities in a way that their governments have failed to do.    IN AN ODDLY fortuitous way, it was the state\\u2019s record-breaking drought that threw water inequality in the state\\u2019s impoverished rural communities into high relief. After three consecutive years of low rainfall, a problem made worse by excessive pumping by desperate farmers, a small town in Tulare county called East Porterville became the poster child of the drought when roughly 860 domestic wells ran dry.   But East Porterville\\u2019s travails started long before the drought. Like Matheny Tract, it hadn\\u2019t had drinkable water for years and relied on antiquated private wells. \\u201cThese low-income families can\\u2019t afford $20,000 to $30,000 to drill a well,\\u201d says Fred Beltran, a volunteer with nonprofit Porterville Area Coordinating Council, a social service organization in East Porterville. \\u201cTherefore, they\\u2019re dabbling in this contaminated water\\u2014giving it to their babies, their elderlies and what not.\\u201d The two most common hazards in this part of the Central Valley are arsenic, which occurs naturally, and nitrates from fertilizers spread over vast fields and from animal wastes that leach into the groundwater. Nitrates and other contaminants are particularly dangerous for children, putting newborns at risk for deformities, serious illness and even death. Most of the nitrates lurking in drinking water wells today were applied to fields decades ago, so the contamination levels will likely get worse in coming years as the chemicals continue to filter into the groundwater, according to scientists at the University of California at Davis.   Unlike bigger, more prosperous cities, which have enough ratepayers to afford to treat piped-in surface and groundwater, small systems are at the mercy of groundwater pumped from shallow wells. Statewide, 400 small rural systems have contaminated water, with many schools among them. An estimated 160,000 Californians live in unincorporated communities with iffy drinking water, according to the Public Policy Institute of California\\u2019s Water Center.   The landscape of Matheny Tract is emblematic of these passed-over places: dirt paths instead of sidewalks, mudhole streets without curbs or gutters, a handful of broken streetlights and cars speeding past nonexistent stop signs. A dusty irrigation ditch, once swimmable, cleaves the community. Land values remain depressed and there is a lack of public investment. Most households rely on aging septic tanks that are beginning to fail, creating another imminent threat to the drinking water.   \\u201cMatheny Tract is a kin of Flint,\\u201d says Michelle Wilde Anderson, a Stanford law professor who has studied both places and has written extensively on infrastructure. \\u201cBoth are older communities in which we\\u2019ve failed to invest in basic needs.\\u201d   Settled by white Okies fleeing the Dust Bowl and so-called black Okies fleeing the Jim Crow South, the Tract was developed in the 1940s by Edwin Matheny, a traveling salesman with a penchant for real estate who dispensed teat balm and other sundries from a retrofitted Plymouth. While some nearby towns had race restrictions written into real estate deeds, Matheny was happy to sell to African-Americans, some of whose descendants still reside in their original family homes.   \\u201cSomewhere along the way nobody bothered with Matheny, so poverty became a self-fulfilling prophecy,\\u201d says Laurel Firestone, an attorney and co-director of The Community Water Center, a sponsor of the Human Right to Water bill. \\u201cIt remains poor because there was no investment in basic services to make it a nice place to live.\\u201d   Like hundreds of unincorporated communities nationally, the Tract has been \\u201cmapped out of democracy,\\u201d in Anderson\\u2019s words. Residents under county jurisdiction don\\u2019t vote in city elections; they don\\u2019t receive municipal services, and their low property tax base contributes to their being overlooked. Many of these communities lie just beyond, and some within, the boundaries of cities that are happy to provide safe drinking water to brand new subdivisions\\u2014even ones outside their jurisdiction that they plan to annex\\u2014while ignoring impoverished areas in their midst.   \\u201cMost counties are not in the water business,\\u201d observes Bill Chiat, dean of the California State Association of Counties Institute. \\u201cSo you\\u2019ve got these disadvantaged communities, and no one is required to provide them water.\\u201d   The relationship between political disenfranchisement, poverty and tainted water is not lost on Leonard Ogans, part of a committee of Matheny residents who, with help from attorneys at the nonprofit Leadership Counsel for Justice and Accountability in Fresno, have battled for nine years for decent infrastructure. On Ogans\\u2019 front porch, a handmade protest sign hangs over a photograph of a black child. It reads: \\u201cJUST WATER BABY.\\u201d   THE RIGHT TO water concept is decades old. In South Africa and several other countries it is even enshrined in the national constitution. But it wasn\\u2019t until an international water and sanitation expert arrived in the Central Valley on a fact-finding mission that politicians in California began to take notice.   The right to water is rooted in the idea that clean water is fundamental to life and health, and foundational to human dignity. It ties into the concept of environmental justice, in which poor, politically isolated populations around the world are often most vulnerable to a lack of access to safe and affordable drinking water.   In California, the richest agricultural area of the richest country in the world, the impoverished farmworkers on whom the industry depends must also endure drinking water contaminated by agricultural chemicals. In this context, thinking about water as a right rather than as a mere utility or civic amenity makes compelling sense, says Colin Bailey, an attorney and executive director of the Environmental Justice Coalition for Water in Sacramento. \\u201cDemocracy is about equal opportunity and equality before the law,\\u201d he says. \\u201cIf people don\\u2019t have access to this basic necessity, there is no social contract.\\u201d   In 2011, Catarina de Albuquerque, from the United Nations, compared conditions in the tiny Central Valley community of Seville (about 25 miles northeast of Tulare) to the Third World. \\u201cShe shamed us all,\\u201d recalls former State Assemblyman Mike Eng.   The shame continued when residents from affected communities and their supporters assembled on the steps of the State Capitol in Sacramento bearing plastic bottles of contaminated water\\u2014nitrates from Tooleville, arsenic from Alpaugh\\u2014which they mixed into a \\u201cCentral Valley blend\\u201d as a mock gift to legislators. Eng, with backing from environmental and water justice advocates, citizen-activists and faith groups, especially the Unitarian Universalist Service Committee, which has been a strong voice in water justice issues, authored the right to water law, which passed in 2012. But the bill didn\\u2019t include an enforcement mechanism. That came later with SB88, which passed last June.   That law requires municipalities to supply drinking water to disadvantaged unincorporated communities in close proximity. If a city resists, or the two parties cannot figure out a way to merge voluntarily into one water system, the State Water Resources Control Board, part of the California Environmental Protection Agency, has the power to order consolidation.   In anticipation of consolidation, the state had already laid nearly $5 million worth of water lines beneath Matheny. But when Tulare changed its mind, a ping-pong match of litigation ensued that left Matheny residents with brand new pipes\\u2014but no water running through them. In March, the state EPA broke the logjam, invoking its new power for the first time, forcing a marriage between Tulare and Matheny Tract.   Nearby Farmersville (pop.: 11, 000) where the walnut dehydrator sits across from Family Dollar, took a slightly more generous approach toward a needy nearby community. The city successfully sought state and federal funds to voluntarily merge its system with impoverished Cameron Creek Colony when its wells dried up during the drought. \\u201cAny community can do it,\\u201d says the city\\u2019s Latino mayor, Gregorio Gomez. \\u201cIt\\u2019s just the willingness has to be there.\\u201d   Had Matheny Tract been developed today, it is less likely that basic human needs would have been ignored in the first place. The state\\u2019s Right to Water bill presaged water as a burgeoning national civil rights issue led by the National Coalition for Legislation on Affordable Water, a group that started after thousands of Detroit residents had their water shut off in 2014.   In California, it has shifted the narrative and set the stage for a major water bond measure and a more transparent process, including a forthcoming publicly accessible human right to water database on every water system that\\u2019s out of compliance.   Spurred by public hearings and the prospect of legal action by the state, the city of Tulare agreed earlier this month to send clean water to Matheny, which is scheduled to arrive June 1. Residents will then become official city water customers.   In anticipation, new water meters are being installed and fire hydrants swaddled in plastic bags wait for what Leonard Ogans calls \\u201cturn-on day\\u201d\\u2014 the moment when fresh, clean, genuinely healthy water starts flowing through the faucets of Matheny Tract for the first time in decades.   \\u201cWe\\u2019re not looking for a handout,\\u201d Ogans\\u2019 truck driver neighbor Vance McKinney explains. \\u201cHelp us help ourselves. That\\u2019s all we\\u2019ve been asking.\\u201d\",\n          \"Who is Mallika Sherawat, the Bollywood actress 'punched and tear-gassed' by masked men in Paris? \\u2014  Weeks after Kim Kardashian was robbed at gunpoint in Paris another global superstar has fall victim to the dark side of the French capital. Bollywood actress Mallika Sherawat was tear-gassed and beaten during an attempted robbery, police revealed on Thursday.   According to French newspaper Le Parisien, the international model and a male companion were set upon by three masked men as they arrived back at their apartment complex on Rue de La Faisanderie in Paris on Friday (11 November). The outspoken feminist, whose real name is Reema Lamba, previously described India as \\\"regressive\\\", while speaking out against attacks \\u2013 gang rapes and honour killings \\u2013 on women in her home country.   Sherawat is a prominent actress in India having starred in a number of high-profile Bollywood films including Khwahish and Murder.   She made the crossover to Hollywood, with appearances in 2010's adventure-horror Hisss and 2011's Politics of Love alongside Brian J White.   The 40-year-old adopted the screen name of Mallika to avoid confusion with other actresses named Reema.   In the run up to the US elections she endorsed Hillary Clinton by sharing a snap of herself and Barack Obama with the caption: \\\"Dear President Obama I have always supported the Democratic Party, praying for #hillaryclinton victory#presidentobama#uspresidentialelection #womenpower#hillaryforpresident\\\"   Her online fan base includes almost two million followers on Twitter and 200K followers on Instragram. Unlike Karadashian, Sherawat has remained active on her social media accounts despite her ordeal. In recent days she has shared a handful of selfies and also throwback images from her various film projects.   Sherawat was previously married to and has no children. She now divides her time between Los Angeles, US and India.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# Assuming the file uploaded is 'example.csv'\n",
        "filename = 'CW_DataSet.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q733lbE7utiy",
        "outputId": "85f55326-2a40-46f2-b0e6-ffb23973f4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_id                                               text  \\\n",
            "0           1  'Abhorrent' bottle attack on young Rangers fan...   \n",
            "1           2  'Afghan Girl' in iconic National Geographic ph...   \n",
            "2           3  'My whole family has been wiped out': Victims ...   \n",
            "3           4  'RHONY' STAR JULES WAINSTEIN Estranged Husband...   \n",
            "4           5  'Swam for their life': More survivors of Levia...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  abhorrent bottle attack young ranger fan celti...  \n",
            "1  afghan girl iconic national geographic photo a...  \n",
            "2  whole family wipe victim dreamworld tragedy re...  \n",
            "3  rhony star jule wainstein estrange husband sue...  \n",
            "4  swam life survivor leviathan ii tragedy sue to...  \n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    tokens = [nlp(word)[0].lemma_ for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXnkX9dju8Xs",
        "outputId": "924f43c8-1fb8-47e1-999d-9a8ad688f2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehwpUlezkW6",
        "outputId": "a58326c2-eb4c-4c84-b93e-254ff662d76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_id                                     processed_text\n",
            "0           1  abhorrent bottle attack young ranger fan celti...\n",
            "1           2  afghan girl iconic national geographic photo a...\n",
            "2           3  whole family wipe victim dreamworld tragedy re...\n",
            "3           4  rhony star jule wainstein estrange husband sue...\n",
            "4           5  swam life survivor leviathan ii tragedy sue to...\n"
          ]
        }
      ],
      "source": [
        "data.drop('text', axis=1, inplace=True)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whRRY4Usz14E",
        "outputId": "4829d29b-4b4f-441b-b56d-c23d2a2ddc9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_id                                     processed_text  emotion\n",
            "0           1  abhorrent bottle attack young ranger fan celti...    angry\n",
            "1           2  afghan girl iconic national geographic photo a...  neutral\n",
            "2           3  whole family wipe victim dreamworld tragedy re...      sad\n",
            "3           4  rhony star jule wainstein estrange husband sue...  neutral\n",
            "4           5  swam life survivor leviathan ii tragedy sue to...      sad\n"
          ]
        }
      ],
      "source": [
        "def label_emotion(text):\n",
        "    text_lower = text.lower()\n",
        "\n",
        "\n",
        "    if any(keyword in text_lower for keyword in ['angry', 'attack', 'assault']):\n",
        "        return 'angry'\n",
        "    elif any(keyword in text_lower for keyword in ['happy', 'celebrate', 'joy']):\n",
        "        return 'happy'\n",
        "    elif any(keyword in text_lower for keyword in ['sad', 'tragedy', 'grief']):\n",
        "        return 'sad'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "data['emotion'] = data['processed_text'].apply(label_emotion)\n",
        "\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "OPnN5O7L0Bco",
        "outputId": "630520b8-aab1-4212-8551-87a17f884441"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion Distribution:\n",
            "emotion\n",
            "neutral    0.507177\n",
            "angry      0.327751\n",
            "sad        0.098086\n",
            "happy      0.066986\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "emotion_counts = data['emotion'].value_counts()\n",
        "emotion_ratios = emotion_counts / len(data)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pie(emotion_ratios, labels=emotion_ratios.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Emotion Distribution')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "emotion_counts = data['emotion'].value_counts()\n",
        "\n",
        "emotion_ratios = emotion_counts / len(data)\n",
        "\n",
        "print(\"Emotion Distribution:\")\n",
        "print(emotion_ratios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "iL3-MfNi0FXR",
        "outputId": "9ab1aecd-55f6-422f-e1f6-c04480d3c13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion Distribution:\n",
            "emotion\n",
            "angry      0.327751\n",
            "neutral    0.325359\n",
            "happy      0.239234\n",
            "sad        0.107656\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Function to get synonyms\n",
        "def get_synonyms(words):\n",
        "    synonyms = set()\n",
        "    for word in words:\n",
        "        for syn in wordnet.synsets(word):\n",
        "            for lemma in syn.lemmas():\n",
        "                synonyms.add(lemma.name().lower())\n",
        "    return list(synonyms)\n",
        "\n",
        "# Define initial keywords\n",
        "angry_keywords = ['angry', 'attack', 'assault']\n",
        "happy_keywords = ['happy', 'celebrate', 'joy']\n",
        "sad_keywords = ['sad', 'tragedy', 'grief']\n",
        "\n",
        "extended_happy_keywords = get_synonyms(happy_keywords)\n",
        "extended_sad_keywords = get_synonyms(sad_keywords)\n",
        "\n",
        "happy_keywords.extend(extended_happy_keywords)\n",
        "sad_keywords.extend(extended_sad_keywords)\n",
        "\n",
        "\n",
        "def label_emotion(text):\n",
        "    text_lower = text.lower()\n",
        "\n",
        "\n",
        "    if any(keyword in text_lower for keyword in angry_keywords):\n",
        "        return 'angry'\n",
        "    elif any(keyword in text_lower for keyword in happy_keywords):\n",
        "        return 'happy'\n",
        "    elif any(keyword in text_lower for keyword in sad_keywords):\n",
        "        return 'sad'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "\n",
        "data['emotion'] = data['processed_text'].apply(label_emotion)\n",
        "\n",
        "emotion_counts = data['emotion'].value_counts()\n",
        "\n",
        "emotion_ratios = emotion_counts / len(data)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pie(emotion_ratios, labels=emotion_ratios.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Emotion Distribution')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "emotion_counts = data['emotion'].value_counts()\n",
        "\n",
        "# Calculate the ratio or proportion of each emotion\n",
        "emotion_ratios = emotion_counts / len(data)\n",
        "\n",
        "print(\"Emotion Distribution:\")\n",
        "print(emotion_ratios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCkyNYx0O66",
        "outputId": "df1a4817-a411-4938-da50-5c51dd14c7b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_id                                     processed_text  emotion  \\\n",
            "0           1  abhorrent bottle attack young ranger fan celti...    angry   \n",
            "1           2  afghan girl iconic national geographic photo a...  neutral   \n",
            "2           3  whole family wipe victim dreamworld tragedy re...      sad   \n",
            "3           4  rhony star jule wainstein estrange husband sue...  neutral   \n",
            "4           5  swam life survivor leviathan ii tragedy sue to...      sad   \n",
            "\n",
            "               0   0    00   01   02   03  ...   úl  úl    ús  ús     ü   ün  \\\n",
            "0  0.516113  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "1  0.483480  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "2  0.539360  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "3  0.500407  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "4  0.527123  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   ünn    ă   ăn  ăne  \n",
            "0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 10273 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(data['processed_text'])\n",
        "\n",
        "\n",
        "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "df_with_tfidf = pd.concat([data[['article_id', 'processed_text', 'emotion']], tfidf_df], axis=1)\n",
        "\n",
        "\n",
        "print(df_with_tfidf.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of CNN"
      ],
      "metadata": {
        "id": "VZkOfUblJgkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NtslJ0pu0S0U",
        "outputId": "9bde43e4-b54b-435b-9b58-ba627d878bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 675ms/step - accuracy: 0.2540 - loss: 1.3756 - val_accuracy: 0.3284 - val_loss: 1.2489\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.3310 - loss: 1.3518 - val_accuracy: 0.3284 - val_loss: 1.3048\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.3504 - loss: 1.3330 - val_accuracy: 0.3284 - val_loss: 1.2935\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2892 - loss: 1.3715 - val_accuracy: 0.1642 - val_loss: 1.3288\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2687 - loss: 1.3487 - val_accuracy: 0.3284 - val_loss: 1.2842\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.3644 - loss: 1.3378 - val_accuracy: 0.4030 - val_loss: 1.2934\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4106 - loss: 1.3267 - val_accuracy: 0.3582 - val_loss: 1.3013\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4270 - loss: 1.3214 - val_accuracy: 0.4925 - val_loss: 1.2677\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.3834 - loss: 1.2741 - val_accuracy: 0.3433 - val_loss: 1.2369\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4721 - loss: 1.1977 - val_accuracy: 0.2537 - val_loss: 1.3254\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step\n",
            "CNN Accuracy: 0.32142857142857145\n",
            "CNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.57      0.15      0.24        27\n",
            "       happy       0.30      0.96      0.46        24\n",
            "     neutral       0.00      0.00      0.00        27\n",
            "         sad       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.32        84\n",
            "   macro avg       0.22      0.28      0.17        84\n",
            "weighted avg       0.27      0.32      0.21        84\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Prepare the data\n",
        "X = df_with_tfidf.drop(['article_id', 'processed_text', 'emotion'], axis=1).values\n",
        "y = df_with_tfidf['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for CNN (adding a single channel dimension)\n",
        "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(128, 5, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    Conv1D(64, 5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_cnn = model.predict(X_test_cnn)\n",
        "y_pred_cnn_classes = np.argmax(y_pred_cnn, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy_cnn = accuracy_score(y_test, y_pred_cnn_classes)\n",
        "print(\"CNN Accuracy:\", accuracy_cnn)\n",
        "print(\"CNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn_classes, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HH4oixJc0ZBe",
        "outputId": "059df95a-c7e5-4555-acf8-b284edd2dc15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 785ms/step - accuracy: 0.2550 - loss: 1.3902 - val_accuracy: 0.3295 - val_loss: 1.3862\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2546 - loss: 1.3866 - val_accuracy: 0.1591 - val_loss: 1.3874\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2557 - loss: 1.3860 - val_accuracy: 0.1591 - val_loss: 1.3897\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2619 - loss: 1.3858 - val_accuracy: 0.1591 - val_loss: 1.3888\n",
            "Epoch 5/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2955 - loss: 1.3845 - val_accuracy: 0.1591 - val_loss: 1.3903\n",
            "Epoch 6/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2862 - loss: 1.3833 - val_accuracy: 0.2273 - val_loss: 1.3910\n",
            "Epoch 7/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.2114 - loss: 1.3877 - val_accuracy: 0.1591 - val_loss: 1.3924\n",
            "Epoch 8/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2168 - loss: 1.3873 - val_accuracy: 0.1591 - val_loss: 1.3900\n",
            "Epoch 9/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2911 - loss: 1.3837 - val_accuracy: 0.1591 - val_loss: 1.3937\n",
            "Epoch 10/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.3143 - loss: 1.3821 - val_accuracy: 0.1591 - val_loss: 1.3969\n",
            "Epoch 11/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2540 - loss: 1.3876 - val_accuracy: 0.1591 - val_loss: 1.3925\n",
            "Epoch 12/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2626 - loss: 1.3839 - val_accuracy: 0.1591 - val_loss: 1.3925\n",
            "Epoch 13/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2705 - loss: 1.3846 - val_accuracy: 0.1591 - val_loss: 1.3925\n",
            "Epoch 14/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2610 - loss: 1.3832 - val_accuracy: 0.1591 - val_loss: 1.3935\n",
            "Epoch 15/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2364 - loss: 1.3857 - val_accuracy: 0.1591 - val_loss: 1.3936\n",
            "Epoch 16/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2708 - loss: 1.3855 - val_accuracy: 0.1591 - val_loss: 1.3906\n",
            "Epoch 17/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2615 - loss: 1.3829 - val_accuracy: 0.1591 - val_loss: 1.3935\n",
            "Epoch 18/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.2765 - loss: 1.3842 - val_accuracy: 0.2273 - val_loss: 1.3947\n",
            "Epoch 19/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.3076 - loss: 1.3800 - val_accuracy: 0.2727 - val_loss: 1.3876\n",
            "Epoch 20/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2082 - loss: 1.3900 - val_accuracy: 0.2273 - val_loss: 1.3861\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step\n",
            "CNN Accuracy: 0.23636363636363636\n",
            "CNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.00      0.00      0.00        21\n",
            "       happy       0.00      0.00      0.00        30\n",
            "     neutral       0.24      1.00      0.38        26\n",
            "         sad       0.00      0.00      0.00        33\n",
            "\n",
            "    accuracy                           0.24       110\n",
            "   macro avg       0.06      0.25      0.10       110\n",
            "weighted avg       0.06      0.24      0.09       110\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "X = df_with_tfidf.drop(['article_id', 'processed_text', 'emotion'], axis=1).values\n",
        "y = df_with_tfidf['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for CNN (adding a single channel dimension)\n",
        "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(128, 5, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    Conv1D(64, 5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    Conv1D(32, 3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_cnn = model.predict(X_test_cnn)\n",
        "y_pred_cnn_classes = np.argmax(y_pred_cnn, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy_cnn = accuracy_score(y_test, y_pred_cnn_classes)\n",
        "print(\"CNN Accuracy:\", accuracy_cnn)\n",
        "print(\"CNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn_classes, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3_Zrn2BZ15Nv",
        "outputId": "71594e10-5be7-4eaa-b83b-74a1b9f566d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593ms/step - accuracy: 0.2079 - loss: 1.3873 - val_accuracy: 0.2841 - val_loss: 1.3853\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 561ms/step - accuracy: 0.2415 - loss: 1.3866 - val_accuracy: 0.1591 - val_loss: 1.3879\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 559ms/step - accuracy: 0.2516 - loss: 1.3855 - val_accuracy: 0.3295 - val_loss: 1.3861\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 559ms/step - accuracy: 0.2541 - loss: 1.3853 - val_accuracy: 0.1591 - val_loss: 1.3891\n",
            "Epoch 5/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 562ms/step - accuracy: 0.2962 - loss: 1.3824 - val_accuracy: 0.1591 - val_loss: 1.3925\n",
            "Epoch 6/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.2573 - loss: 1.3879 - val_accuracy: 0.2273 - val_loss: 1.3927\n",
            "Epoch 7/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 567ms/step - accuracy: 0.2840 - loss: 1.3841 - val_accuracy: 0.1591 - val_loss: 1.3929\n",
            "Epoch 8/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2607 - loss: 1.3847 - val_accuracy: 0.1591 - val_loss: 1.3931\n",
            "Epoch 9/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 561ms/step - accuracy: 0.2584 - loss: 1.3846 - val_accuracy: 0.1591 - val_loss: 1.3978\n",
            "Epoch 10/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step - accuracy: 0.2593 - loss: 1.3841 - val_accuracy: 0.1591 - val_loss: 1.3977\n",
            "Epoch 11/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 560ms/step - accuracy: 0.2814 - loss: 1.3849 - val_accuracy: 0.1591 - val_loss: 1.3993\n",
            "Epoch 12/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step - accuracy: 0.2286 - loss: 1.3891 - val_accuracy: 0.1591 - val_loss: 1.3959\n",
            "Epoch 13/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2507 - loss: 1.3874 - val_accuracy: 0.1591 - val_loss: 1.3944\n",
            "Epoch 14/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 562ms/step - accuracy: 0.2651 - loss: 1.3865 - val_accuracy: 0.1591 - val_loss: 1.3941\n",
            "Epoch 15/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 562ms/step - accuracy: 0.2663 - loss: 1.3863 - val_accuracy: 0.1591 - val_loss: 1.3918\n",
            "Epoch 16/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2627 - loss: 1.3858 - val_accuracy: 0.1591 - val_loss: 1.3953\n",
            "Epoch 17/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step - accuracy: 0.2529 - loss: 1.3867 - val_accuracy: 0.1591 - val_loss: 1.3976\n",
            "Epoch 18/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2941 - loss: 1.3792 - val_accuracy: 0.2273 - val_loss: 1.3991\n",
            "Epoch 19/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.2898 - loss: 1.3838 - val_accuracy: 0.1591 - val_loss: 1.3966\n",
            "Epoch 20/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.2860 - loss: 1.3812 - val_accuracy: 0.1591 - val_loss: 1.3963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c59222339a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c59222339a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step\n",
            "LSTM Accuracy: 0.2727272727272727\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.00      0.00      0.00        21\n",
            "       happy       0.27      1.00      0.43        30\n",
            "     neutral       0.00      0.00      0.00        26\n",
            "         sad       0.00      0.00      0.00        33\n",
            "\n",
            "    accuracy                           0.27       110\n",
            "   macro avg       0.07      0.25      0.11       110\n",
            "weighted avg       0.07      0.27      0.12       110\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "X = df_with_tfidf.drop(['article_id', 'processed_text', 'emotion'], axis=1).values\n",
        "y = df_with_tfidf['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for LSTM (adding a single channel dimension)\n",
        "X_train_lstm = np.expand_dims(X_train, axis=2)\n",
        "X_test_lstm = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lstm = model.predict(X_test_lstm)\n",
        "y_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy_lstm = accuracy_score(y_test, y_pred_lstm_classes)\n",
        "print(\"LSTM Accuracy:\", accuracy_lstm)\n",
        "print(\"LSTM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lstm_classes, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0bvuvk90whDE",
        "outputId": "c734bd64-7b0b-4ee4-f03e-ffc4d4c7206a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 596ms/step - accuracy: 0.2176 - loss: 1.3859 - val_accuracy: 0.1818 - val_loss: 1.3868\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step - accuracy: 0.3131 - loss: 1.3741 - val_accuracy: 0.1932 - val_loss: 1.3746\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2739 - loss: 1.3737 - val_accuracy: 0.3068 - val_loss: 1.3564\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.3324 - loss: 1.3482 - val_accuracy: 0.2727 - val_loss: 1.3660\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 563ms/step - accuracy: 0.3388 - loss: 1.3608 - val_accuracy: 0.3068 - val_loss: 1.3290\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.3083 - loss: 1.3545 - val_accuracy: 0.2841 - val_loss: 1.3379\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.3237 - loss: 1.3273 - val_accuracy: 0.2727 - val_loss: 1.3394\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.3021 - loss: 1.3560 - val_accuracy: 0.2727 - val_loss: 1.3116\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 567ms/step - accuracy: 0.2772 - loss: 1.3352 - val_accuracy: 0.2955 - val_loss: 1.3342\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 570ms/step - accuracy: 0.3181 - loss: 1.3253 - val_accuracy: 0.1818 - val_loss: 1.3112\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.3003 - loss: 1.3366 - val_accuracy: 0.3523 - val_loss: 1.3104\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 569ms/step - accuracy: 0.2823 - loss: 1.3546 - val_accuracy: 0.3068 - val_loss: 1.3062\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2808 - loss: 1.3144 - val_accuracy: 0.2841 - val_loss: 1.3057\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 570ms/step - accuracy: 0.2478 - loss: 1.3504 - val_accuracy: 0.2841 - val_loss: 1.2979\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.3853 - loss: 1.3222 - val_accuracy: 0.2727 - val_loss: 1.2946\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 569ms/step - accuracy: 0.3394 - loss: 1.3104 - val_accuracy: 0.3068 - val_loss: 1.3386\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.2821 - loss: 1.3428 - val_accuracy: 0.4091 - val_loss: 1.2932\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.4018 - loss: 1.2841 - val_accuracy: 0.4318 - val_loss: 1.2984\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2633 - loss: 1.3995 - val_accuracy: 0.2500 - val_loss: 1.2960\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2979 - loss: 1.3585 - val_accuracy: 0.3295 - val_loss: 1.3368\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.3311 - loss: 1.3396 - val_accuracy: 0.3523 - val_loss: 1.2962\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2970 - loss: 1.3181 - val_accuracy: 0.3523 - val_loss: 1.2856\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2677 - loss: 1.3418 - val_accuracy: 0.3523 - val_loss: 1.2797\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.3486 - loss: 1.3200 - val_accuracy: 0.3523 - val_loss: 1.2795\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.3021 - loss: 1.3300 - val_accuracy: 0.3523 - val_loss: 1.2716\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.2983 - loss: 1.3282 - val_accuracy: 0.3295 - val_loss: 1.2717\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.2552 - loss: 1.3125 - val_accuracy: 0.3409 - val_loss: 1.2688\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 569ms/step - accuracy: 0.2953 - loss: 1.3035 - val_accuracy: 0.3409 - val_loss: 1.2577\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 569ms/step - accuracy: 0.2781 - loss: 1.3286 - val_accuracy: 0.3409 - val_loss: 1.2649\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 574ms/step - accuracy: 0.3112 - loss: 1.3424 - val_accuracy: 0.3409 - val_loss: 1.2972\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.3644 - loss: 1.3269 - val_accuracy: 0.3295 - val_loss: 1.2558\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 567ms/step - accuracy: 0.3720 - loss: 1.2764 - val_accuracy: 0.3409 - val_loss: 1.2955\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 570ms/step - accuracy: 0.3363 - loss: 1.3016 - val_accuracy: 0.3295 - val_loss: 1.3179\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 573ms/step - accuracy: 0.3526 - loss: 1.2445 - val_accuracy: 0.2727 - val_loss: 1.5472\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 567ms/step - accuracy: 0.3518 - loss: 1.3955 - val_accuracy: 0.3409 - val_loss: 1.2567\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.3142 - loss: 1.3285 - val_accuracy: 0.3523 - val_loss: 1.2634\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.3302 - loss: 1.3143 - val_accuracy: 0.3295 - val_loss: 1.2891\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.3438 - loss: 1.3160 - val_accuracy: 0.2273 - val_loss: 1.2992\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.3008 - loss: 1.3495 - val_accuracy: 0.2273 - val_loss: 1.2670\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.3445 - loss: 1.2837 - val_accuracy: 0.3409 - val_loss: 1.2513\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 568ms/step - accuracy: 0.3470 - loss: 1.3181 - val_accuracy: 0.3750 - val_loss: 1.2520\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 570ms/step - accuracy: 0.3722 - loss: 1.2996 - val_accuracy: 0.3523 - val_loss: 1.2600\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.3685 - loss: 1.2850 - val_accuracy: 0.3636 - val_loss: 1.2470\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.3143 - loss: 1.3237 - val_accuracy: 0.2955 - val_loss: 1.2635\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 571ms/step - accuracy: 0.3812 - loss: 1.2879 - val_accuracy: 0.3523 - val_loss: 1.3780\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 565ms/step - accuracy: 0.3237 - loss: 1.3833 - val_accuracy: 0.3068 - val_loss: 1.2935\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2813 - loss: 1.3224 - val_accuracy: 0.3068 - val_loss: 1.2776\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 564ms/step - accuracy: 0.3722 - loss: 1.2770 - val_accuracy: 0.3182 - val_loss: 1.2703\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 567ms/step - accuracy: 0.3102 - loss: 1.2933 - val_accuracy: 0.3409 - val_loss: 1.2949\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.2949 - loss: 1.3328 - val_accuracy: 0.3182 - val_loss: 1.2909\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step\n",
            "LSTM Accuracy: 0.34545454545454546\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.00      0.00      0.00        21\n",
            "       happy       0.75      0.10      0.18        30\n",
            "     neutral       0.28      1.00      0.43        26\n",
            "         sad       0.75      0.27      0.40        33\n",
            "\n",
            "    accuracy                           0.35       110\n",
            "   macro avg       0.44      0.34      0.25       110\n",
            "weighted avg       0.49      0.35      0.27       110\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "X = df_with_tfidf.drop(['article_id', 'processed_text', 'emotion'], axis=1).values\n",
        "y = df_with_tfidf['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_resampled = scaler.fit_transform(X_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for LSTM (adding a single channel dimension)\n",
        "X_train_lstm = np.expand_dims(X_train, axis=2)\n",
        "X_test_lstm = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lstm = model.predict(X_test_lstm)\n",
        "y_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy_lstm = accuracy_score(y_test, y_pred_lstm_classes)\n",
        "print(\"LSTM Accuracy:\", accuracy_lstm)\n",
        "print(\"LSTM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lstm_classes, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sl9IJfCYxpqX",
        "outputId": "05165941-88c4-4456-f551-f06044c9a0c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.2357 - loss: 1.3868 - val_accuracy: 0.1591 - val_loss: 1.3910\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2735 - loss: 1.3785 - val_accuracy: 0.4318 - val_loss: 1.3734\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4078 - loss: 1.3448 - val_accuracy: 0.2159 - val_loss: 1.3728\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3574 - loss: 1.3173 - val_accuracy: 0.4318 - val_loss: 1.3182\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6258 - loss: 1.2266 - val_accuracy: 0.6023 - val_loss: 1.2351\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6278 - loss: 1.0993 - val_accuracy: 0.5909 - val_loss: 1.1497\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.9801 - val_accuracy: 0.5909 - val_loss: 1.0766\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7810 - loss: 0.7697 - val_accuracy: 0.5114 - val_loss: 1.0526\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.6247 - val_accuracy: 0.6477 - val_loss: 0.9507\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.4183 - val_accuracy: 0.6932 - val_loss: 0.8592\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9609 - loss: 0.3093 - val_accuracy: 0.6477 - val_loss: 0.8718\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.2264 - val_accuracy: 0.6591 - val_loss: 0.8604\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.2020 - val_accuracy: 0.7273 - val_loss: 0.8266\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0981 - val_accuracy: 0.6705 - val_loss: 0.9176\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0970 - val_accuracy: 0.7273 - val_loss: 0.8339\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0857 - val_accuracy: 0.6818 - val_loss: 0.8366\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0530 - val_accuracy: 0.6023 - val_loss: 1.0011\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0410 - val_accuracy: 0.7159 - val_loss: 0.9006\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.6705 - val_loss: 0.9550\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0287 - val_accuracy: 0.6932 - val_loss: 0.9479\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.6932 - val_loss: 0.9602\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 0.6818 - val_loss: 0.9260\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.6932 - val_loss: 0.9649\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.6932 - val_loss: 0.9746\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.6818 - val_loss: 1.0260\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.6932 - val_loss: 1.0191\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.6364 - val_loss: 1.0543\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.7045 - val_loss: 1.0155\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.7045 - val_loss: 0.9896\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.6705 - val_loss: 1.1088\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.6932 - val_loss: 1.0633\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.6932 - val_loss: 1.0628\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.6818 - val_loss: 1.0414\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6932 - val_loss: 1.0773\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.6705 - val_loss: 1.1389\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.6818 - val_loss: 1.1531\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.6932 - val_loss: 1.0923\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.6932 - val_loss: 1.0921\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7045 - val_loss: 1.1181\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7045 - val_loss: 1.1428\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.6818 - val_loss: 1.1155\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7045 - val_loss: 1.1514\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7045 - val_loss: 1.1348\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6818 - val_loss: 1.1256\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6818 - val_loss: 1.1977\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6477 - val_loss: 1.1540\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.6705 - val_loss: 1.1638\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6591 - val_loss: 1.2145\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6932 - val_loss: 1.1699\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.6932 - val_loss: 1.1222\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
            "MLP Accuracy: 0.6545454545454545\n",
            "MLP Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.67      0.52        21\n",
            "       happy       0.67      0.73      0.70        30\n",
            "     neutral       0.70      0.27      0.39        26\n",
            "         sad       0.85      0.88      0.87        33\n",
            "\n",
            "    accuracy                           0.65       110\n",
            "   macro avg       0.66      0.64      0.62       110\n",
            "weighted avg       0.68      0.65      0.64       110\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "X = df_with_tfidf.drop(['article_id', 'processed_text', 'emotion'], axis=1).values\n",
        "y = df_with_tfidf['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the MLP model\n",
        "mlp_model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "mlp_history = mlp_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "y_pred_mlp_classes = np.argmax(y_pred_mlp, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp_classes)\n",
        "print(\"MLP Accuracy:\", accuracy_mlp)\n",
        "print(\"MLP Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_mlp_classes, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df_with_tfidf.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHnlfQStn2Xy",
        "outputId": "2617611a-c433-4b12-8184-00569dfa5b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_id                                     processed_text  emotion  \\\n",
            "0           1  abhorrent bottle attack young ranger fan celti...    angry   \n",
            "1           2  afghan girl iconic national geographic photo a...  neutral   \n",
            "2           3  whole family wipe victim dreamworld tragedy re...      sad   \n",
            "3           4  rhony star jule wainstein estrange husband sue...  neutral   \n",
            "4           5  swam life survivor leviathan ii tragedy sue to...      sad   \n",
            "\n",
            "               0   0    00   01   02   03  ...   úl  úl    ús  ús     ü   ün  \\\n",
            "0  0.516113  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "1  0.483480  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "2  0.539360  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "3  0.500407  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "4  0.527123  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   ünn    ă   ăn  ăne  \n",
            "0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 10273 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "data = df_with_tfidf[['processed_text', 'emotion']]\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "X_tokenized = tokenizer(data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='np', max_length=512)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tokenized['input_ids'], y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the resampled data back to tensors\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "# Prepare attention masks\n",
        "attention_masks_train = tf.convert_to_tensor(np.where(X_train != 0, 1, 0), dtype=tf.int32)\n",
        "attention_masks_test = tf.convert_to_tensor(np.where(X_test != 0, 1, 0), dtype=tf.int32)\n",
        "\n",
        "# Load the BERT model\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Build the transformer model\n",
        "input_ids = Input(shape=(512,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Get the last hidden state\n",
        "cls_token = bert_output[:, 0, :]  # Get the CLS token representation\n",
        "dropout = Dropout(0.3)(cls_token)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train, attention_masks_train], y_train, epochs=3, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict([X_test, attention_masks_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"BERT Accuracy:\", accuracy)\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "7ESgRWJ5ot8J",
        "outputId": "a3a7ffb9-5ec4-4bfe-f182-b0bc911c5b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model_5' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_5' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-87460968e4cb>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the CLS token representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_5' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_5' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "data = df_with_tfidf[['processed_text', 'emotion']]\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "X_tokenized = tokenizer(data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='np', max_length=512)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tokenized['input_ids'], y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the resampled data back to tensors\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "# Prepare attention masks\n",
        "attention_masks_train = tf.convert_to_tensor(np.where(X_train != 0, 1, 0), dtype=tf.int32)\n",
        "attention_masks_test = tf.convert_to_tensor(np.where(X_test != 0, 1, 0), dtype=tf.int32)\n",
        "\n",
        "# Load the BERT model\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Build the transformer model\n",
        "input_ids = Input(shape=(512,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Get the last hidden state\n",
        "cls_token = bert_output[:, 0, :]  # Get the CLS token representation\n",
        "dropout = Dropout(0.3)(cls_token)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train, attention_masks_train], y_train, epochs=3, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict([X_test, attention_masks_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"BERT Accuracy:\", accuracy)\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "tjvrGWtJpguW",
        "outputId": "10cceb8d-96d6-4a77-a6ad-68392dff980e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model_6' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_6' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-87460968e4cb>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the CLS token representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_6' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_6' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "data = df_with_tfidf[['processed_text', 'emotion']]\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "X_tokenized = tokenizer(data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='np', max_length=512)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tokenized['input_ids'], y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the resampled data back to tensors\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "# Prepare attention masks\n",
        "attention_masks_train = tf.convert_to_tensor(np.where(X_train != 0, 1, 0), dtype=tf.int32)\n",
        "attention_masks_test = tf.convert_to_tensor(np.where(X_test != 0, 1, 0), dtype=tf.int32)\n",
        "\n",
        "# Load the BERT model\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Build the transformer model\n",
        "input_ids = Input(shape=(512,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Get the last hidden state\n",
        "cls_token = bert_output[:, 0, :]  # Get the CLS token representation\n",
        "dropout = Dropout(0.3)(cls_token)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train, attention_masks_train], y_train, epochs=3, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict([X_test, attention_masks_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"BERT Accuracy:\", accuracy)\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "zVfgU9DmphS0",
        "outputId": "4470ed10-3e05-4940-9b40-d9592e60d7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model_7' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_7' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-87460968e4cb>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the CLS token representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_7' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_7' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Prepare the data\n",
        "data = df_with_tfidf[['processed_text', 'emotion']]\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "X_tokenized = tokenizer(data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='np', max_length=512)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tokenized['input_ids'], y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the resampled data back to tensors\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "\n",
        "# Prepare attention masks\n",
        "attention_masks_train = tf.convert_to_tensor(np.where(X_train != 0, 1, 0), dtype=tf.int32)\n",
        "attention_masks_test = tf.convert_to_tensor(np.where(X_test != 0, 1, 0), dtype=tf.int32)\n",
        "\n",
        "# Load the BERT model\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Build the transformer model\n",
        "input_ids = Input(shape=(512,), dtype=tf.int32, name=\"input_ids\")\n",
        "# Remove the attention_mask Input layer\n",
        "# attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "bert_output = bert_model(input_ids, attention_mask=attention_masks_train)[0]  # Use the pre-computed attention mask\n",
        "cls_token = bert_output[:, 0, :]\n",
        "dropout = Dropout(0.3)(cls_token)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "model = Model(inputs=input_ids, outputs=output)  # Update model inputs\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train, attention_masks_train], y_train, epochs=3, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict([X_test, attention_masks_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"BERT Accuracy:\", accuracy)\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "Y-21z93YqbPG",
        "outputId": "850f54d2-b2a3-4f93-ef12-9d97c9c923da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model_9' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_bert_model_9' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=tf.Tensor(shape=(438, 512), dtype=int32)\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-773cf01f6bcb>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_masks_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use the pre-computed attention mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0;34mf\"Data of type {type(main_input)} is not allowed only {allowed_types} is accepted for\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;34mf\" {main_input_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_9' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_bert_model_9' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=tf.Tensor(shape=(438, 512), dtype=int32)\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26jaF_RZqbyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "lD_rTBVurVea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = df_with_tfidf.copy()  # Assuming df_with_tfidf is your DataFrame with processed_text and emotion columns\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['processed_text'])\n",
        "X = tokenizer.texts_to_sequences(data['processed_text'])\n",
        "X = pad_sequences(X, padding='post')\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=X.shape[1]))\n",
        "model.add(SimpleRNN(128, return_sequences=False))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"RNN Accuracy:\", accuracy)\n",
        "print(\"RNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L79bAynHrWSa",
        "outputId": "91929c99-e581-451c-b962-8b5e507e69f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.2460 - loss: 1.3876 - val_accuracy: 0.3134 - val_loss: 1.3843\n",
            "Epoch 2/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.3059 - loss: 1.3966 - val_accuracy: 0.4328 - val_loss: 1.3442\n",
            "Epoch 3/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3476 - loss: 1.4720 - val_accuracy: 0.3284 - val_loss: 1.6183\n",
            "Epoch 4/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3385 - loss: 1.5287 - val_accuracy: 0.3284 - val_loss: 1.3592\n",
            "Epoch 5/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3047 - loss: 1.5017 - val_accuracy: 0.4328 - val_loss: 1.2813\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step\n",
            "RNN Accuracy: 0.32142857142857145\n",
            "RNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.32      1.00      0.49        27\n",
            "       happy       0.00      0.00      0.00        24\n",
            "     neutral       0.00      0.00      0.00        27\n",
            "         sad       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.32        84\n",
            "   macro avg       0.08      0.25      0.12        84\n",
            "weighted avg       0.10      0.32      0.16        84\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = df_with_tfidf.copy()  # Assuming df_with_tfidf is your DataFrame with processed_text and emotion columns\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['processed_text'])\n",
        "X = tokenizer.texts_to_sequences(data['processed_text'])\n",
        "X = pad_sequences(X, padding='post')\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['emotion'])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the enhanced RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=X.shape[1]))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"Enhanced RNN Accuracy:\", accuracy)\n",
        "print(\"Enhanced RNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGlnuxfzrW89",
        "outputId": "3e6eef5e-6d87-4436-c4af-d604d43f479c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 9s/step - accuracy: 0.3155 - loss: 1.3739 - val_accuracy: 0.3284 - val_loss: 1.2986\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9s/step - accuracy: 0.2823 - loss: 1.3369 - val_accuracy: 0.3284 - val_loss: 1.3142\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9s/step - accuracy: 0.3146 - loss: 1.3164 - val_accuracy: 0.3284 - val_loss: 1.2698\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 9s/step - accuracy: 0.3354 - loss: 1.3065 - val_accuracy: 0.3284 - val_loss: 1.2867\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9s/step - accuracy: 0.2648 - loss: 1.3506 - val_accuracy: 0.3284 - val_loss: 1.3421\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9s/step - accuracy: 0.3161 - loss: 1.3385 - val_accuracy: 0.3284 - val_loss: 1.2895\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9s/step - accuracy: 0.3039 - loss: 1.3299 - val_accuracy: 0.4328 - val_loss: 1.2862\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9s/step - accuracy: 0.3034 - loss: 1.3341 - val_accuracy: 0.4328 - val_loss: 1.2933\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9s/step - accuracy: 0.3200 - loss: 1.3360 - val_accuracy: 0.3284 - val_loss: 1.2890\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9s/step - accuracy: 0.3079 - loss: 1.3116 - val_accuracy: 0.3284 - val_loss: 1.2857\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n",
            "Enhanced RNN Accuracy: 0.32142857142857145\n",
            "Enhanced RNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.00      0.00      0.00        27\n",
            "       happy       0.00      0.00      0.00        24\n",
            "     neutral       0.32      1.00      0.49        27\n",
            "         sad       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.32        84\n",
            "   macro avg       0.08      0.25      0.12        84\n",
            "weighted avg       0.10      0.32      0.16        84\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otguffGWwLNf",
        "outputId": "d0ac132f-bf45-4cd5-cd78-c1fb7f37bc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikeras-0.13.0 scikit-learn-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Prepare the data\n",
        "X = data['processed_text'].values\n",
        "y = data['emotion'].values\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Tokenize the text\n",
        "X_tokenized = tokenizer(X.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tokenized['input_ids'].numpy(), y_encoded)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = np.where(X_resampled != 0, 1, 0)\n",
        "\n",
        "# Split attention masks\n",
        "attention_masks_train, attention_masks_test = train_test_split(attention_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the BERT model\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Build the transformer model\n",
        "input_ids = Input(shape=(X_train.shape[1],), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_masks_input = Input(shape=(X_train.shape[1],), dtype=tf.int32, name=\"attention_masks\")\n",
        "bert_output = bert_model(input_ids, attention_mask=attention_masks_input)[1]  # Get the pooled output\n",
        "dropout = Dropout(0.3)(bert_output)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_ids, attention_masks_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train, attention_masks_train], y_train, epochs=3, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict([X_test, attention_masks_test])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the results\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "print(\"BERT Accuracy:\", accuracy)\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c90049c0bf14826a5ef81b79fda116f",
            "7d3b0343df574f69a25294a3c6b4d3b9",
            "b1e361f414e941b093a41149311c15af",
            "8a04fbc62645488187d917f6f11020a4",
            "58aafda289f844f8842c0ebec63cb668",
            "8bea96a064f6435580b842f80421eb20",
            "031d13d5e36b4fa0bc3392ed96d956fb",
            "df9f1646687141b0b61ef86e43fa977d",
            "b0a288295e7b4ee2b9c590d1fba85d67",
            "eedca2b1a1044eb5878c77e85a2ee44c",
            "383a2a01549e405e813ca611e639d8d5",
            "7b03b981f04144b19ad3dae4e6635e79",
            "9a938b1568924ffda777aa79cdc0399d",
            "c3d56e745ed0491297067a61110f0a6f",
            "7b12b48143874c18b9f165e6fb71e21b",
            "65ef7692e2e547fbabfec0d1e9e21376",
            "d8f700ac763047289341052d1ca29483",
            "c793fb9597c5478c9238306f499ac990",
            "5994e0a828244e19802028eb875d6e30",
            "df0e1cad72e8433399814c0e62da94bd",
            "30603a9ad4bc40e5b5254eb89bd82c2e",
            "68ea74682f0b4915a3815c63d015fe64",
            "2fb8b8faae55455c857e299ed0e35873",
            "a57b6e651d524b4ba7b6c0aaaa13f6c7",
            "763e96e93f924f9ebab4027af5cbe7ad",
            "45cebd86b5474830b0f4839d7f73a05d",
            "4242011f10a740b09bac06874a4fe9eb",
            "0fd75f9d6b0942c3926e763ba4ff0fac",
            "08b15a4b2ddd49338d91fa7293538011",
            "1deafb44ecdd40edb1119bb10c32d174",
            "23f4c7630dfb49878b51424b6bce59b8",
            "629adf83e6e24fc78ca09722821d176b",
            "28bd0b22b17e4b7e8d8c2ab8b84b727c",
            "ae90df69b01e40398a4a22259a831279",
            "9a517044107a4206a7a39f1df9588aab",
            "1ecf1acda99a4b0cb468649f8df9a606",
            "49116a22b7ec4696adb4d108ef465cd2",
            "37bb63161b4147a6ae6f5d58974b6983",
            "eef3a249409448acb66b466cbae68f69",
            "6501bf5f91994d24a9f5a5d858d5cc40",
            "40e0f3d36ce141369d78da16ed6dca59",
            "2b9c866acb8141339afc77386803c68c",
            "d178bd7eae9f41c586ee336d6c9fcdab",
            "0ebff2851c1645ef8562056a22bdc9ba",
            "912d5e47e7dc4b0597a93451ec7c59a7",
            "907cc5c90921485db01a333b821e7b7a",
            "94773af1b0c645e6bc5f11b1bc5beba1",
            "cb7ea704aac44b688c5defdbaa581046",
            "6166fb39283d40799a194bcab5bab887",
            "7f30d4ddbca245dfa7b2b6d3e487d3c8",
            "7785944223e2432893ebfeee7bf5ca05",
            "745975d973a74e1ab50143567c7f8324",
            "fe63d75b3c6c463fb8b8df1807f7681c",
            "cdf79379d7ee496987d5b9026105d78e",
            "f2deb648af5b4546a8b732b08faa562a"
          ]
        },
        "id": "aX5rHLYSxGD7",
        "outputId": "12678f0d-2311-4a7a-9280-b81cec96d362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c90049c0bf14826a5ef81b79fda116f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b03b981f04144b19ad3dae4e6635e79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fb8b8faae55455c857e299ed0e35873"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae90df69b01e40398a4a22259a831279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "912d5e47e7dc4b0597a93451ec7c59a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_masks>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ae9fb98ae613>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mattention_masks_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_masks_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the pooled output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 512), dtype=int32, sparse=None, name=attention_masks>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VOwoB3yxL_Pr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c90049c0bf14826a5ef81b79fda116f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d3b0343df574f69a25294a3c6b4d3b9",
              "IPY_MODEL_b1e361f414e941b093a41149311c15af",
              "IPY_MODEL_8a04fbc62645488187d917f6f11020a4"
            ],
            "layout": "IPY_MODEL_58aafda289f844f8842c0ebec63cb668"
          }
        },
        "7d3b0343df574f69a25294a3c6b4d3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bea96a064f6435580b842f80421eb20",
            "placeholder": "​",
            "style": "IPY_MODEL_031d13d5e36b4fa0bc3392ed96d956fb",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b1e361f414e941b093a41149311c15af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df9f1646687141b0b61ef86e43fa977d",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a288295e7b4ee2b9c590d1fba85d67",
            "value": 48
          }
        },
        "8a04fbc62645488187d917f6f11020a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedca2b1a1044eb5878c77e85a2ee44c",
            "placeholder": "​",
            "style": "IPY_MODEL_383a2a01549e405e813ca611e639d8d5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.56kB/s]"
          }
        },
        "58aafda289f844f8842c0ebec63cb668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bea96a064f6435580b842f80421eb20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031d13d5e36b4fa0bc3392ed96d956fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df9f1646687141b0b61ef86e43fa977d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a288295e7b4ee2b9c590d1fba85d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eedca2b1a1044eb5878c77e85a2ee44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383a2a01549e405e813ca611e639d8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b03b981f04144b19ad3dae4e6635e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a938b1568924ffda777aa79cdc0399d",
              "IPY_MODEL_c3d56e745ed0491297067a61110f0a6f",
              "IPY_MODEL_7b12b48143874c18b9f165e6fb71e21b"
            ],
            "layout": "IPY_MODEL_65ef7692e2e547fbabfec0d1e9e21376"
          }
        },
        "9a938b1568924ffda777aa79cdc0399d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f700ac763047289341052d1ca29483",
            "placeholder": "​",
            "style": "IPY_MODEL_c793fb9597c5478c9238306f499ac990",
            "value": "vocab.txt: 100%"
          }
        },
        "c3d56e745ed0491297067a61110f0a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5994e0a828244e19802028eb875d6e30",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df0e1cad72e8433399814c0e62da94bd",
            "value": 231508
          }
        },
        "7b12b48143874c18b9f165e6fb71e21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30603a9ad4bc40e5b5254eb89bd82c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_68ea74682f0b4915a3815c63d015fe64",
            "value": " 232k/232k [00:00&lt;00:00, 666kB/s]"
          }
        },
        "65ef7692e2e547fbabfec0d1e9e21376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f700ac763047289341052d1ca29483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c793fb9597c5478c9238306f499ac990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5994e0a828244e19802028eb875d6e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0e1cad72e8433399814c0e62da94bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30603a9ad4bc40e5b5254eb89bd82c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ea74682f0b4915a3815c63d015fe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb8b8faae55455c857e299ed0e35873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a57b6e651d524b4ba7b6c0aaaa13f6c7",
              "IPY_MODEL_763e96e93f924f9ebab4027af5cbe7ad",
              "IPY_MODEL_45cebd86b5474830b0f4839d7f73a05d"
            ],
            "layout": "IPY_MODEL_4242011f10a740b09bac06874a4fe9eb"
          }
        },
        "a57b6e651d524b4ba7b6c0aaaa13f6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd75f9d6b0942c3926e763ba4ff0fac",
            "placeholder": "​",
            "style": "IPY_MODEL_08b15a4b2ddd49338d91fa7293538011",
            "value": "tokenizer.json: 100%"
          }
        },
        "763e96e93f924f9ebab4027af5cbe7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deafb44ecdd40edb1119bb10c32d174",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23f4c7630dfb49878b51424b6bce59b8",
            "value": 466062
          }
        },
        "45cebd86b5474830b0f4839d7f73a05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629adf83e6e24fc78ca09722821d176b",
            "placeholder": "​",
            "style": "IPY_MODEL_28bd0b22b17e4b7e8d8c2ab8b84b727c",
            "value": " 466k/466k [00:00&lt;00:00, 914kB/s]"
          }
        },
        "4242011f10a740b09bac06874a4fe9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd75f9d6b0942c3926e763ba4ff0fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b15a4b2ddd49338d91fa7293538011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1deafb44ecdd40edb1119bb10c32d174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23f4c7630dfb49878b51424b6bce59b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629adf83e6e24fc78ca09722821d176b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bd0b22b17e4b7e8d8c2ab8b84b727c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae90df69b01e40398a4a22259a831279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a517044107a4206a7a39f1df9588aab",
              "IPY_MODEL_1ecf1acda99a4b0cb468649f8df9a606",
              "IPY_MODEL_49116a22b7ec4696adb4d108ef465cd2"
            ],
            "layout": "IPY_MODEL_37bb63161b4147a6ae6f5d58974b6983"
          }
        },
        "9a517044107a4206a7a39f1df9588aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef3a249409448acb66b466cbae68f69",
            "placeholder": "​",
            "style": "IPY_MODEL_6501bf5f91994d24a9f5a5d858d5cc40",
            "value": "config.json: 100%"
          }
        },
        "1ecf1acda99a4b0cb468649f8df9a606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e0f3d36ce141369d78da16ed6dca59",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b9c866acb8141339afc77386803c68c",
            "value": 570
          }
        },
        "49116a22b7ec4696adb4d108ef465cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d178bd7eae9f41c586ee336d6c9fcdab",
            "placeholder": "​",
            "style": "IPY_MODEL_0ebff2851c1645ef8562056a22bdc9ba",
            "value": " 570/570 [00:00&lt;00:00, 48.8kB/s]"
          }
        },
        "37bb63161b4147a6ae6f5d58974b6983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef3a249409448acb66b466cbae68f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6501bf5f91994d24a9f5a5d858d5cc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e0f3d36ce141369d78da16ed6dca59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9c866acb8141339afc77386803c68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d178bd7eae9f41c586ee336d6c9fcdab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebff2851c1645ef8562056a22bdc9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "912d5e47e7dc4b0597a93451ec7c59a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_907cc5c90921485db01a333b821e7b7a",
              "IPY_MODEL_94773af1b0c645e6bc5f11b1bc5beba1",
              "IPY_MODEL_cb7ea704aac44b688c5defdbaa581046"
            ],
            "layout": "IPY_MODEL_6166fb39283d40799a194bcab5bab887"
          }
        },
        "907cc5c90921485db01a333b821e7b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f30d4ddbca245dfa7b2b6d3e487d3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_7785944223e2432893ebfeee7bf5ca05",
            "value": "model.safetensors: 100%"
          }
        },
        "94773af1b0c645e6bc5f11b1bc5beba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745975d973a74e1ab50143567c7f8324",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe63d75b3c6c463fb8b8df1807f7681c",
            "value": 440449768
          }
        },
        "cb7ea704aac44b688c5defdbaa581046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf79379d7ee496987d5b9026105d78e",
            "placeholder": "​",
            "style": "IPY_MODEL_f2deb648af5b4546a8b732b08faa562a",
            "value": " 440M/440M [00:01&lt;00:00, 296MB/s]"
          }
        },
        "6166fb39283d40799a194bcab5bab887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f30d4ddbca245dfa7b2b6d3e487d3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7785944223e2432893ebfeee7bf5ca05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "745975d973a74e1ab50143567c7f8324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe63d75b3c6c463fb8b8df1807f7681c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdf79379d7ee496987d5b9026105d78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2deb648af5b4546a8b732b08faa562a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}